# -*- coding: utf-8 -*-
"""Stable Diffusion - Exploring modern models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nRAGQZvc8k6FvZbkGwAXW37_FtZrORCR

# Stable Diffusion - Exploring modern models

##  Installations
"""

!pip install diffusers
!pip install -q accelerate transformers xformers safetensors mediapy

"""## Imports and functions"""

from diffusers import DiffusionPipeline
import torch
import random
import sys
import gc
from PIL import Image

#@title Useful functions

## Show image
def show_img(imgs, scale=1, rows=1, cols=None):
  if cols==None:
    cols = len(imgs)
  assert len(imgs) == rows * cols

  w, h = imgs[0].size
  w, h = int(w * scale), int(h * scale)

  grid = Image.new('RGB', size = (cols * w, rows * h))
  grid_w, grid_h = grid.size

  for i, img in enumerate(imgs):
    img = img.resize((w, h), Image.Resampling.LANCZOS)
    grid.paste(img, box=(i % cols * w, i // cols * h))
  return grid


# Pipeline creation
def sd_schedulers(pipe, scheduler):
  from diffusers import (
    DDPMScheduler,
    DDIMScheduler,
    PNDMScheduler,
    LMSDiscreteScheduler,
    EulerDiscreteScheduler,
    EulerAncestralDiscreteScheduler,
    DPMSolverSinglestepScheduler,
    DPMSolverMultistepScheduler,
    KDPM2DiscreteScheduler,
    KDPM2AncestralDiscreteScheduler,
    UniPCMultistepScheduler)

  if (scheduler == "DDPM"):
    pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "DDIM"):
    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "PNDM"):
    pipe.scheduler = PNDMScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "LMS"):
    pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "LMS Karras"):
    pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)
  elif (scheduler == "Euler"):
    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "Euler A"):
    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "DPM++ 2M"):
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
  elif (scheduler == "DPM++ 2M Karras"):
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)
  elif (scheduler == "DPM++ 2M SDE"):
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, algorithm_type="sde-dpmsolver++")
  elif (scheduler == "DPM++ 2M SDE Karras"):
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True, algorithm_type="sde-dpmsolver++")
  elif (scheduler == "DPM2 Karras"):
    pipe.scheduler = KDPM2DiscreteScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)
  elif (scheduler == "DPM2 a Karras"):
    pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)
  elif (scheduler == "UniPC"):
    pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)

  return pipe


def sdxl_pipeline(id_model="stabilityai/stable-diffusion-xl-base-1.0", scheduler="Euler A", use_safetensors=True):
  if (use_safetensors):
    pipe = DiffusionPipeline.from_pretrained(id_model, torch_dtype=torch.float16, use_safetensors=True, variant="fp16")
  else:
    pipe = DiffusionPipeline.from_pretrained(id_model, torch_dtype=torch.float16, variant="fp16")
  pipe.to('cuda')
  pipe.safety_checker = None

  pipe = sd_schedulers(pipe, scheduler)

  return pipe


def sd_pipeline(id_model="runwayml/stable-diffusion-v1-5", scheduler="Euler A"):
  from diffusers import StableDiffusionPipeline

  pipe = StableDiffusionPipeline.from_pretrained(id_model, torch_dtype=torch.float16, safety_checker = None)
  pipe = pipe.to("cuda")
  pipe.safety_checker = None
  pipe.enable_attention_slicing()
  pipe.enable_xformers_memory_efficient_attention()

  pipe = sd_schedulers(pipe, scheduler)

  return pipe


def sd_generate(v, pipe, prompt, neg_prompt, num_images, width, height, prop, inference_steps, cfg, seed):
  gc.collect()
  torch.cuda.empty_cache()

  # selects appropriate size/ratio based on version
  if v == "sdxl":
    sizes = prop_sdxl
  else:
    sizes = prop_sd

  if prop != "":
    width = sizes[prop]['x']
    height = sizes[prop]['y']

  if (seed < 0):
    seed = random.randint(0, sys.maxsize) # generates a random value

  print("Seed: {}".format(str(seed)))
  generator = torch.Generator(device='cuda').manual_seed(seed)

  img = pipe(
        prompt=prompt,
        negative_prompt=neg_prompt,
        num_images_per_prompt=num_images,
        width=width,
        height=height,
        num_inference_steps=inference_steps,
        guidance_scale=cfg,
        generator=generator).images
  return img


# Proportions (aspect ratio)
prop_sdxl = {
"1:1" :  { 'x' : 1024  , 'y' :  1024 },
"12:5" :  { 'x' : 1536  , 'y' :  640 },
"7:4" :   { 'x' : 1344  , 'y' :  768 },
"19:13" : { 'x' : 1216  , 'y' :  832 },
"9:7" :   { 'x' : 1152 , 'y' : 896 },
"7:9" :   { 'x' : 896  , 'y' : 1152  },
"13:19" : { 'x' : 832  , 'y' :  1216 },
"4:7" :   { 'x' : 768  , 'y' :  1344 },
"5:12" :  { 'x' : 640  , 'y' :  1536 }
}

prop_sd = {
"1:1" :  { 'x' : 512  , 'y' : 512 },
"3:2" :  { 'x' : 768  , 'y' : 512 },
"2:3" :  { 'x' : 512  , 'y' : 768 },
"2:1" :  { 'x' : 1024 , 'y' : 512 },
"1:2" :  { 'x' : 512  , 'y' : 1024 },
}

"""## Models

To find the most modern models, go to

https://huggingface.co/models?library=diffusers&sort=trending

* This link will show a list of models compatible with the implementation we use (via Diffusers), sorted by the most trending models. If you prefer, click the button located at the top right to sort in another way, such as by the highest number of likes.
* You can use the search field to check if you can find models that are published in other repositories, such as CivitAI.


**Some SD 1.5 models to generate excellent and professional results:**
- Realistic
  - [**epiCRealism**](https://huggingface.co/emilianJR/epiCRealism)
  - [**epiCPhotoGasm**](https://huggingface.co/twn39/epicphotogasm)
  - [**Realistic Vision**](https://huggingface.co/SG161222/Realistic_Vision_V6.0_B1_noVAE)
  * Pay attention to the version. Realistic Vision, for example, has several: 6.0, 5.1, etc.
- Other types of models:
  - [**DreamShaper**](https://huggingface.co/Lykon/dreamshaper-8) - general purpose model that aims to do everything well (photos, paintings, anime...), although with a lower level of realism
  - [**ToonYou**](https://huggingface.co/stablediffusionapi/toonyou) - model focused on cartoon style illustration
- Other models focused on realism:
  - [AbsoluteReality](https://civitai.com/models/81458/absolutereality)
  - [CyberRealistic](https://civitai.com/models/15003)
  - [majicMIX realistic](https://civitai.com/models/43331)
  - [Photon](https://civitai.com/models/84728)
  - [Juggernaut](https://civitai.com/models/46422)
  - [ICBINP](https://civitai.com/models/28059)
  - [ChilloutMix](https://civitai.com/models/6424)
  - [Analog Madness](https://civitai.com/models/8030/analog-madness-realistic-model)


The first ones are listed below.

We make them available for field selection, using the forms option in Colab, so it is practical to switch. This select field also allows free editing, so you can simply paste into this field the ID of the desired model that you found in Hugging Face.


> **Selecting a model**

* The code below must be executed whenever you want to change the model.

* The first time you load the model it will take a while, as it needs to be downloaded.

* And the first time you run it, a message may appear asking for access to a token, select 'Cancel'.

"""

id_model = "emilianJR/epiCRealism" # @param ["emilianJR/epiCRealism", "SG161222/Realistic_Vision_V6.0_B1_noVAE", "twn39/epicphotogasm", "Lykon/dreamshaper-8", "stablediffusionapi/toonyou"] {allow-input: true}

gc.collect()
torch.cuda.empty_cache()
pipe = None
pipe = sd_pipeline(id_model=id_model, scheduler="DPM++ 2M Karras")

"""## Generation

Below you can check the code that will run SD and generate the image. This code combines the functions created above at the beginning of this Colab.


### Parameters

***First of all, we recommend visiting the model description page to find out which parameters are best suited for the model you are using. (check the slides presentation for this section)***

> **Guidance scale (CFG)**

 * Base model: the default value is 7, but you can vary it as you want.
 * Custom models: An important note for custom models (especially those without a refiner) is that most of them recommend a lower value (like 3.5 or 4). If you have time to experiment you can vary these values, as it depends on your goal and desired style. But if you are uncertain, take a look at the recommendations on the model page.
* Ultimately, the most effective approach to selecting the correct CFG value is through experimentation. Generate images using multiple values and choose your preferred result.
* Why would you want to test variations of these parameters? For instance, if you use DPM++ 2M Karras, in many cases the image obtained with 20 steps will not be better or worse than the one generated with 30, they will just be slightly different. With more steps the image will be modified even more, but that doesn't mean it's changed for the better, it just means it has changed. You're the one who will decide which one has the best details.  With DPM++, for most models you will find that 20 steps is enough.


> **Inference steps**

 * Base model: 25~50 steps. It also depends a lot on scheduler you are using (e.g. DPM 2M++ Karras requires 20 steps, while Euler A requires at least twice this value).
* Custom models: generally requires less. See the recommendations on the model description, some may recommend more steps and others requires less (such as Turbo models).

> **Seed**

* In the code below, we defined like this: If you set seed = -1 then it will generate a random value for the seed.
The number of the seed will be printed above the image (in the output cell) so if you like that generation you can save this seed, and paste it in the field, so that will "lock" it.

> **Scheduler**

* Overall, DPM++ 2M Karras and Euler A are usually the best choices, they are an almost perfect balance between speed and quality. But if you're experimenting, you can test all the others.
* DPM++ SDE Karras is also excellent and overall may be slightly better than the 2M, but it is a little slower.
 * DPM usually requires only 20 steps. But if the image seems a little incomplete, try increasing the number of steps.  If you are using a custom model, it's a good practice to always see the scheduler recommendation on the model page.

> **Size**

* The standard size of the SDXL model is 1024x1024, unlike the non-XL (e.g. SD 1.5) which is 512x512. Check the slides for more details.

* **`[!]`** How the size selection works in the code below: if you select any value for the `prop` field then it will be assigned the width and height corresponding to that proportion / aspect ratio, therefore, it will replace the values entered in width and height. If you want to manually enter the width and height values, then simply fill them in these corresponding fields and leave the `prop` value empty.

> **Negative Prompt**

For more realistic results, the use of negative prompts is essential on non-XL models. You can use this general purpose negative prompt below to generate more realistic images:

* `semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, nude, nsfw, anime, deformed iris, deformed pupils, mutated hands and fingers, deformed, distorted, disfigured, ugly, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs  `


The first example below uses a prompt we created in the "Exploring the Prompts" colab
"""

prompt = "darth vader in ancient egypt, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3" #@param {type:"string"}
neg_prompt = "semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, nude, nsfw, anime, deformed iris, deformed pupils, mutated hands and fingers, deformed, distorted, disfigured, ugly, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs" #@param {type:"string"}
width = 512                #@param {type:"number"}
height = 512               #@param {type:"number"}
prop = "1:1" # @param [ "", "1:1", "3:2", "2:3", "2:1", "1:2" ]
inference_steps = 25   #@param {type:"number"}
cfg = 7.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sd", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.9)

"""**`Here we won't explain in detail all the keywords shown in this Colab. Please review the "Prompt Engineering" section.`**

### üì∑ Generating realistic photographs of people

Use keywords like: `close up`, `portrait`, `stunning photo of `, etc.

Some examples of prompts:


* `close up photo of a woman with short brown hair wearing dark clothes`

* `closeup photo of a beautiful woman, dark hair, candid, wearing short sleeves and a skirt, in a street photography setting, golden hour lighting`

* `photo of a blond with bun hair, dim light, bokeh background`

* `closeup portrait photo of man wearing a suit, city street, bokeh`


**`[!] Recommendations:`**
* Test different parameters. We recommend changing the scheduler. As mentioned, DPM is best suited for realistic images, but we still recommend testing not only DPM variations but also other schedulers. And remember that some schedulers require different numbers of steps for better results.  

* When generating photos of people, it is more interesting to choose portrait mode, where the height of the image is greater than the width. Therefore, choose proportions appropriate for this image format (such as 2:3)
"""

id_model = "emilianJR/epiCRealism" # @param ["emilianJR/epiCRealism", "SG161222/Realistic_Vision_V6.0_B1_noVAE", "twn39/epicphotogasm", "Lykon/dreamshaper-8", "stablediffusionapi/toonyou"] {allow-input: true}
pipe = sd_pipeline(id_model=id_model, scheduler="DPM++ 2M Karras")

prompt = "close up photo of a woman with short brown hair wearing dark clothes" #@param {type:"string"}
neg_prompt = "semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, nude, nsfw, anime, deformed iris, deformed pupils, mutated hands and fingers, deformed, distorted, disfigured, ugly, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs" #@param {type:"string"}
width = 512                #@param {type:"number"}
height = 512               #@param {type:"number"}
prop = "2:3" # @param [ "", "1:1", "3:2", "2:3", "2:1", "1:2" ]
inference_steps = 25   #@param {type:"number"}
cfg = 7.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sd", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.9)

"""> **Note:** Below, we will simply copy and paste the code from the block above. In other words, the code you will see below (for each example) is exactly the same as what was presented above, just copied because we want to separate each section/example.

### üåÑ Generating landscapes or scenes
"""

id_model = "SG161222/Realistic_Vision_V6.0_B1_noVAE" # @param ["emilianJR/epiCRealism", "SG161222/Realistic_Vision_V6.0_B1_noVAE", "twn39/epicphotogasm", "Lykon/dreamshaper-8", "stablediffusionapi/toonyou"] {allow-input: true}
pipe = sd_pipeline(id_model=id_model)

prompt = "photo of a mountain landscape during sunset" #@param {type:"string"}
neg_prompt = "semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, nude, nsfw, anime, deformed iris, deformed pupils, mutated hands and fingers, deformed, distorted, disfigured, ugly, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs" #@param {type:"string"}
width = 512                #@param {type:"number"}
height = 512               #@param {type:"number"}
prop = "3:2" # @param [ "", "1:1", "3:2", "2:3", "2:1", "1:2" ]
inference_steps = 25   #@param {type:"number"}
cfg = 7.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sd", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.9)

"""### üè† Generating images of architecture and interiors


* Keywords for interior design/architecture: `modern house interior, sunny, architecture, 8k uhd, dslr, soft lighting, high quality`
* Keywords for external: `modern house, sunny, architecture, 8k uhd, dslr, soft lighting, high quality`

Examples:
* `a professional photograph of an italian architectural modern home, soft render, sunset, golden hour`
* `modern house, sunny, architecture, 8k uhd, dslr, soft lighting, high quality`

Note: Here you could reduce the negative prompt, leaving only keywords relevant to the context, such as: *cartoon, painting, illustration, worst quality, low quality*
"""

prompt = "a professional photograph of an italian architectural modern home, soft render, sunset, golden hour" #@param {type:"string"}
neg_prompt = "semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, nude, nsfw, anime, deformed iris, deformed pupils, mutated hands and fingers, deformed, distorted, disfigured, ugly, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs" #@param {type:"string"}
width = 512                #@param {type:"number"}
height = 512               #@param {type:"number"}
prop = "3:2" # @param [ "", "1:1", "3:2", "2:3", "2:1", "1:2" ]
inference_steps = 25   #@param {type:"number"}
cfg = 7.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sd", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.9)

"""### ‚úè Generating graphic images or drawings

You can also use the realistic models shown above (Epicrealism, Realistic vision or epicPhotogasm) but you will get better and more flexible results using models focused on drawing and illustration style. For the next example, DreamShaper was used, a general-purpose model that handles different types of media and illustrations, but there are also more specific models for each style (as mentioned in colabs 1 and 2 of the course).

For example, for generating stickers, some keywords you can use:
* `die-cut sticker`, `vector`, `contour`, `print ready`, `raw format`
* As for the colors: `pastel colors`, `art colorful design`
* As for the composition: `symmetrical`, `illustration minimalism`, `vector illustration`, `bold lines`
* Other attributes: `cute`, `kawaii` (to make it more ‚Äúcute‚Äù or cartoonish)

Combining these keywords, below you can see some interesting prompt templates to follow:
* `die-cut sticker, cute <object/subject> sticker, white background, illustration minimalism, vector, pastel colors`
* `sticker, vector, <object/subject>, cute, white background, contour, kawaii`
* `sticker of <object/subject>, bold lines, vector illustration, art colorful design, symmetrical, white background, print ready, raw format`

> `[ ! ] Bonus tip: use chatGPT (or other LLM) to generate variations, find new keywords relevant to the topic, or automatically rewrite the prompt. `

Examples:

* `sticker, vector, a classic red car, cute, white background, contour`
* `sticker, vector, shiba dog, cute, white background, contour`
* `die-cut sticker, cute shiba dog sticker, wearing sunglasses, white background, illustration minimalism, vector, pastel colors sticker, vector, an orange cat wearing a tie, cute, white background, contour`

(you can reuse these prompts in the examples with SDXL - which will be seen below - and compare the results)
"""

id_model = "Lykon/dreamshaper-8" # @param ["emilianJR/epiCRealism", "SG161222/Realistic_Vision_V6.0_B1_noVAE", "twn39/epicphotogasm", "Lykon/dreamshaper-8", "stablediffusionapi/toonyou"] {allow-input: true}
pipe = sd_pipeline(id_model=id_model)

prompt = "die-cut sticker, cute shiba dog sticker, wearing sunglasses, white background, illustration minimalism, vector, pastel colors sticker, vector, an orange cat wearing a tie, cute, white background, contour" #@param {type:"string"}
neg_prompt = "semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, nude, nsfw, anime, deformed iris, deformed pupils, mutated hands and fingers, deformed, distorted, disfigured, ugly, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs" #@param {type:"string"}
width = 512                #@param {type:"number"}
height = 512               #@param {type:"number"}
prop = "3:2" # @param [ "", "1:1", "3:2", "2:3", "2:1", "1:2" ]
inference_steps = 25   #@param {type:"number"}
cfg = 7.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sd", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.9)

"""---
# Stable Diffusion XL (SDXL)



The SDXL base model is extremely versatile, it can be useful for a variety of purposes, such as realistic photos, illustrations, drawings and even 3D graphics.

While the SDXL base model can produce excellent results, it is ideal to use it with a Refiner to improve its details and quality. However, in Google Colab, there is no practical way to run the main model together with a Refiner because (as mentioned earlier) this exceeds the available GPU memory, thus resulting in execution errors. Therefore, the idea is to focus on models that do not require a refiner, such as the following:

* [NightVision-XL](https://huggingface.co/imagepipeline/NightVision-XL)
* [Dream Shaper XL (Turbo)](https://huggingface.co/Lykon/dreamshaper-xl-v2-turbo)
* [Juggernaut XL](https://huggingface.co/RunDiffusion/Juggernaut-XL-v9)
* [DynaVision XL](https://huggingface.co/imagepipeline/DynaVision-XL)
* [Open Dalle](https://huggingface.co/dataautogpt3/OpenDalle)
* [ProtoVision XL](https://huggingface.co/stablediffusionapi/protovisionxl-v3)

The first 3 are focused on realism. The others also can achieve some realism, but not as much as these.

In addition to these, we have listed other styles. DynaVision generates a more specific style of illustration, similar to the 3D animations of modern Pixar films. Open Dalle is very powerful for generating illustrations in general and can also achieve realism although it is not its focus, so it can easily generate in different styles.
"""

id_model = "stabilityai/stable-diffusion-xl-base-1.0" # @param [ "imagepipeline/NightVision-XL", "RunDiffusion/Juggernaut-XL-v9", "Lykon/dreamshaper-xl-v2-turbo", "imagepipeline/DynaVision-XL", "dataautogpt3/OpenDalle", "stabilityai/stable-diffusion-xl-base-1.0"] {allow-input: true}

gc.collect()
torch.cuda.empty_cache()
pipe = None
pipe = sdxl_pipeline(id_model=id_model)

"""> Generating with SDXL

Note the higher resolution of the results, due to their larger size

Prompt examples:
* `van gogh painting of an astronaut riding a horse`
* `photo of a rhino, dressed in suit and tie, sitting at a table in a bar with a bar stools, award winning photography`
* `isometric digital art of a medieval village with thatched roofs, a market square, and townsfolk`
"""

prompt = "van gogh painting of an astronaut riding a horse" #@param {type:"string"}
neg_prompt = "" #@param {type:"string"}
width = 1024                #@param {type:"number"}
height = 1024               #@param {type:"number"}
prop = "1:1" # @param [ "", "1:1", "12:5", "7:4", "19:13", "9:7", "7:9", "13:19", "4:7", "5:12"]
inference_steps = 30   #@param {type:"number"}
cfg = 7.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sdxl", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.9)

"""### [ !! ] Memory usage

SDXL models use much more GPU memory. To check the usage, you can use the command below. When changing models many times, it is possible that an out of memory error occurs. If this happens, simply restart the session (select the option from the top menu: Runtime > Restart session). When restarting the session, it is necessary to execute again the imports and function declaration blocks at the beginning of this Colab (just below the title "*Imports and functions*").

"""

!nvidia-smi

"""### üßä Generating with other models
> Using realistic SDXL Models

Examples:
* `photo of a woman with brown hair, in a misty forest, sunset`
* `photo of a panda in a bar, wearing a bowtie, sipping bamboo-infused cocktail, ambient lighting`


Additional notes:
* Remember to vary parameters, such as CFG and Steps.
* The seed will always have a complete influence on the final image, so generate several the image using different seeds. In previous tests we used the XL model without negative prompts, as it was not necessary. But you can test them if you notice that there is still room for improvement in the image.
 * You can add something like: `low quality, ugly, blurred`, and/or other terms that we have already showed in previous negative prompts.
 * But in XL models avoid putting too many negative prompts, usually 5 are already too many (adding several can ‚Äúconfuse‚Äù the model which will result in worsen images), so keep it as simple as possible.

"""

id_model = "imagepipeline/NightVision-XL" # @param [ "imagepipeline/NightVision-XL", "RunDiffusion/Juggernaut-XL-v9", "Lykon/dreamshaper-xl-v2-turbo", "imagepipeline/DynaVision-XL", "dataautogpt3/OpenDalle", "stabilityai/stable-diffusion-xl-base-1.0"] {allow-input: true}

gc.collect()
torch.cuda.empty_cache()
pipe = None
pipe = sdxl_pipeline(id_model=id_model)

prompt = "photo of a woman with brown hair, in a misty forest, sunset" #@param {type:"string"}
neg_prompt = "" #@param {type:"string"}
width = 1024                #@param {type:"number"}
height = 1024               #@param {type:"number"}
prop = "13:19" # @param [ "", "1:1", "12:5", "7:4", "19:13", "9:7", "7:9", "13:19", "4:7", "5:12"]
inference_steps = 35   #@param {type:"number"}
cfg = 7       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sdxl", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.8)

"""> Other model

Again, remember the tip about looking at the parameter recommendations inside the model description page.
The DreamShaper XL for example requires fewer steps and a smaller CFG.

Recommendations:

* Scheduler: DPM++ 2M SDE Karras (with or without 2M)
 * Here in the implementation by Colab using the diffusers library, the DPM++ SDE Karras scheduler is not available for now, however, you can use the DPM++ 2M SDE Karras which leads to a very similar result.
* CFG = 2 (or between 1.5~3.5). This model requires a lower CFG because it is a Turbo model type.
* Steps = 4~8 (in our tests, we got better results with 7 or 8).
 * Since we are using DPM++ 2M SDE Karras as the scheduler here at Colab, a slightly larger number of steps has also shown good results sometimes.

"""

id_model = "Lykon/dreamshaper-xl-v2-turbo" # @param [ "imagepipeline/NightVision-XL", "RunDiffusion/Juggernaut-XL-v9", "Lykon/dreamshaper-xl-v2-turbo", "imagepipeline/DynaVision-XL", "dataautogpt3/OpenDalle", "stabilityai/stable-diffusion-xl-base-1.0"] {allow-input: true}

gc.collect()
torch.cuda.empty_cache()
pipe = None
pipe = sdxl_pipeline(id_model=id_model)

prompt = "gourmet food photo of a burger" #@param {type:"string"}
neg_prompt = "" #@param {type:"string"}
width = 1024                #@param {type:"number"}
height = 1024               #@param {type:"number"}
prop = "19:13" # @param [ "", "1:1", "12:5", "7:4", "19:13", "9:7", "7:9", "13:19", "4:7", "5:12"]
inference_steps = 8   #@param {type:"number"}
cfg = 1.5       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sdxl", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.7)

"""## üé® Generating with SDXL in other styles"""

id_model = "dataautogpt3/OpenDalle" # @param [ "imagepipeline/NightVision-XL", "RunDiffusion/Juggernaut-XL-v9", "Lykon/dreamshaper-xl-v2-turbo", "imagepipeline/DynaVision-XL", "dataautogpt3/OpenDalle", "stabilityai/stable-diffusion-xl-base-1.0"] {allow-input: true}

gc.collect()
torch.cuda.empty_cache()
pipe = None
pipe = sdxl_pipeline(id_model=id_model)

"""Examples to test:

* `cat wearing magician clothes, logo, centered, vector, flat, symmetric, orange and purple tones `
* `sticker, vector, a classic red car, cute, white background, contour`
* `die-cut sticker, cute shiba dog sticker, wearing sunglasses, white background, illustration minimalism, vector, pastel colors`
* `breathtaking illustration of a capybara wearing a modern blue space suit, moon in the background, close shot`
"""

prompt = "cat wearing magician clothes, logo, centered, vector, flat, symmetric, orange and purple tones" #@param {type:"string"}
neg_prompt = "" #@param {type:"string"}
width = 1024                #@param {type:"number"}
height = 1024               #@param {type:"number"}
prop = "1:1" # @param [ "", "1:1", "12:5", "7:4", "19:13", "9:7", "7:9", "13:19", "4:7", "5:12"]
inference_steps = 30   #@param {type:"number"}
cfg = 7       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]

pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sdxl", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.7)

"""## üé® Bonus: Style Selector

If you're still exploring different styles and want to try out a variety of options without wasting time browsing through prompt books, the Style Selector is a handy tool that can save you hours of work. It automatically adjusts the prompt and negative prompt to suit your chosen style, saving you the need to manually adjust each time you want to try something new.

> **Implementation**

* To implement it here in Colab, we did it like this: we created a list with each style name and their respective prompts (positive and negative). These strings will be concatenated to the base prompt, which is the prompt you normally define during generation.

* The keywords used here were based on the original Style Selector, which is widely used by the community and can be found in this repository: https://github.com/ahgsql/StyleSelectorXL

* How to use it: in the code below you will see a new field called `style`, just above the other fields used to define the parameters. Just select the desired style and run the cell - and then perform the generation.

> **Recommended model**

* The Style Selector performs even better when used with highly versatile and general-purpose models, because they can produce good images in a variety of styles. Below, we will use OpenDalle which offers great flexibility and versatility, just as the SDXL model (but can achieve better much results without a refiner). You can also use other models if you like, you should be able to see the some effect even with models focused on a single style.
"""

#@title List of styles

styles = {
"Enhance" : {
"Positive" : "breathtaking {prompt} . award-winning, professional, highly detailed",
"Negative" : "ugly, deformed, noisy, blurry, distorted, grainy",
},
"Anime" : {
"Positive" : "anime artwork {prompt} . anime style, key visual, vibrant, studio anime,  highly detailed",
"Negative" : "photo, deformed, black and white, realism, disfigured, low contrast",
},
"Photographic" : {
"Positive" : "cinematic photo {prompt} . 35mm photograph, film, bokeh, professional, 4k, highly detailed",
"Negative" : "drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly",
},
"Digital art" : {
"Positive" : "concept art {prompt} . digital artwork, illustrative, painterly, matte painting, highly detailed",
"Negative" : "photo, photorealistic, realism, ugly",
},
"Comic book" : {
"Positive" : "comic {prompt} . graphic illustration, comic art, graphic novel art, vibrant, highly detailed",
"Negative" : "photograph, deformed, glitch, noisy, realistic, stock photo",
},
"Fantasy art" : {
"Positive" : "ethereal fantasy concept art of  {prompt} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy",
"Negative" : "photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white",
},
"Analog film" : {
"Positive" : "analog film photo {prompt} . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage",
"Negative" : "painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured",
},
"Neon Punk" : {
"Positive" : "neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional",
"Negative" : "painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured",
},
"Neon Noir" : {
"Positive": "Neon noir {prompt} . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed",
"Negative": "bright, sunny, daytime, low contrast, black and white, sketch, watercolor",
},
"Isometric" : {
"Positive" : "isometric style {prompt} . vibrant, beautiful, crisp, detailed, ultra detailed, intricate",
"Negative" : "deformed, mutated, ugly, disfigured, blur, blurry, noise, noisy, realistic, photographic",
},
"Lowpoly" : {
"Positive" : "low-poly style {prompt} . low-poly game art, polygon mesh, jagged, blocky, wireframe edges, centered composition",
"Negative" : "noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo",
},
"Origami" : {
"Positive" : "origami style {prompt} . paper art, pleated paper, folded, origami art, pleats, cut and fold, centered composition",
"Negative" : "noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo",
},
"Line art" : {
"Positive" : "line art drawing {prompt} . professional, sleek, modern, minimalist, graphic, line art, vector graphics",
"Negative" : "anime, photorealistic, 35mm film, deformed, glitch, blurry, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, mutated, realism, realistic, impressionism, expressionism, oil, acrylic",
},
"Craft clay" : {
"Positive" : "play-doh style {prompt} . sculpture, clay art, centered composition, Claymation",
"Negative" : "sloppy, messy, grainy, highly detailed, ultra textured, photo",
},
"Cinematic" : {
"Positive" : "cinematic film still {prompt} . shallow depth of field, vignette, highly detailed, high budget Hollywood movie, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy",
"Negative" : "anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured",
},
"3d-model" : {
"Positive" : "professional 3d model {prompt} . octane render, highly detailed, volumetric, dramatic lighting",
"Negative" : "ugly, deformed, noisy, low poly, blurry, painting",
},
"Pixel art" : {
"Positive" : "pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics",
"Negative" : "sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic",
},
"Texture" : {
"Positive" : "texture {prompt} top down close-up",
"Negative" : "ugly, deformed, noisy, blurry",
},
"Dystopian" : {
"Positive": "Dystopian style {prompt} . Bleak, post-apocalyptic, somber, dramatic, highly detailed",
"Negative": "ugly, deformed, noisy, blurry, low contrast, cheerful, optimistic, vibrant, colorful",
},
"Retro Game" : {
"Positive": "Retro game art {prompt} . 16-bit, vibrant colors, pixelated, nostalgic, charming, fun",
"Negative": "realistic, photorealistic, 35mm film, deformed, glitch, low contrast, noisy",
},
}

id_model = "dataautogpt3/OpenDalle" # @param [ "imagepipeline/NightVision-XL", "RunDiffusion/Juggernaut-XL-v9", "Lykon/dreamshaper-xl-v2-turbo", "imagepipeline/DynaVision-XL", "dataautogpt3/OpenDalle", "stabilityai/stable-diffusion-xl-base-1.0"] {allow-input: true}

gc.collect()
torch.cuda.empty_cache()
pipe = None
pipe = sdxl_pipeline(id_model=id_model)

style = "Pixel art"  # @param [ "", "Digital art", "Neon Punk", "Neon Noir", "Dystopian", "Pixel art", "Retro Game", "Cinematic", "3d-model", "Enhance" ]

prompt = "cat wearing magician clothes " #@param {type:"string"}
neg_prompt = "" #@param {type:"string"}
width = 1024                #@param {type:"number"}
height = 1024               #@param {type:"number"}
prop = "1:1" # @param [ "", "1:1", "12:5", "7:4", "19:13", "9:7", "7:9", "13:19", "4:7", "5:12"]
inference_steps = 30   #@param {type:"number"}
cfg = 7       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]


if style != "":
  orig_prompt = prompt
  prompt = styles[style]["Positive"].replace("{prompt}", prompt)
  neg_prompt = styles[style]["Negative"]


pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sdxl", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.7)

style = "Digital art"  # @param [ "", "Digital art", "Neon Punk", "Neon Noir", "Dystopian", "Pixel art", "Retro Game", "Cinematic", "3d-model", "Enhance" ]

prompt = "cat wearing wizard clothes " #@param {type:"string"}
neg_prompt = "" #@param {type:"string"}
width = 1024                #@param {type:"number"}
height = 1024               #@param {type:"number"}
prop = "1:1" # @param [ "", "1:1", "12:5", "7:4", "19:13", "9:7", "7:9", "13:19", "4:7", "5:12"]
inference_steps = 30   #@param {type:"number"}
cfg = 7       #@param {type: 'slider', min: 1.0, max: 20.0, step:0.5}
seed = 777                  #@param {type:"number"}
scheduler = "DPM++ 2M SDE Karras" # @param ["DDPM", "DDIM", "PNDM", "LMS", "LMS Karras", "Euler", "Euler A", "DPM++ 2M", "DPM++ 2M Karras", "DPM++ 2M SDE", "DPM++ 2M SDE Karras", "DPM2 Karras", "DPM2 a Karras", "UniPC"]


if style != "":
  orig_prompt = prompt
  prompt = styles[style]["Positive"].replace("{prompt}", prompt)
  neg_prompt = styles[style]["Negative"]


pipe = sd_schedulers(pipe, scheduler)
img = sd_generate("sdxl", pipe, prompt, neg_prompt, 1, width, height, prop, inference_steps, cfg, seed)

show_img(img, scale=0.7)